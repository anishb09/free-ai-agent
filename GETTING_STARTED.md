# ğŸ¤– Free AI Agent - Complete Guide

## ğŸ¯ Quick Start

Your AI agent is ready to use! Run it with:

```bash
python working_free_agent.py
```

## ğŸš€ What You Have

### âœ… Working Features
- **Interactive Chat**: Full conversation interface
- **Offline Operation**: No external APIs required
- **Conversation Management**: Tracks chat history
- **Intent Recognition**: Understands common requests
- **Knowledge Base**: Built-in responses for common topics
- **Rich CLI**: Beautiful terminal interface

### ğŸ—ï¸ Architecture Components

1. **Core Framework** (`ai_agent/core/`)
   - `agent.py`: Main orchestrator
   - `conversation.py`: Chat history management
   - `config.py`: Configuration system

2. **Model System** (`ai_agent/models/`)
   - `base.py`: Abstract model interface
   - `huggingface_model.py`: HuggingFace API (configured)
   - `ollama_model.py`: Local Ollama (available)
   - `simple_chatbot.py`: Rule-based chatbot

3. **Plugin System** (`ai_agent/plugins/`)
   - `base.py`: Plugin interface
   - `example_plugin.py`: Example implementation

## ğŸ”§ Adding Real AI Models

When you get access to AI services, you can easily add them:

### Option 1: OpenAI/Anthropic (Paid)
```bash
# Add to .env file
OPENAI_API_KEY=your_key_here
ANTHROPIC_API_KEY=your_key_here
```

### Option 2: Ollama (Free, Local)
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull a model
ollama pull llama2
```

### Option 3: HuggingFace (Free API)
Your token is already configured! Try different models:
```python
# In ai_agent/models/huggingface_model.py
# Change the model_id to different models
```

## ğŸ¨ Customization

### Adding New Responses
Edit `working_free_agent.py`:

```python
self.knowledge_base = {
    "your_topic": {
        "keyword": "Your response here"
    }
}
```

### Creating Plugins
1. Create new file in `ai_agent/plugins/`
2. Inherit from `BasePlugin`
3. Implement required methods

### Custom Models
1. Create new file in `ai_agent/models/`
2. Inherit from `BaseModel`
3. Implement `generate()` method

## ğŸš€ Usage Examples

### Basic Chat
```python
from working_free_agent import WorkingFreeAgent

agent = WorkingFreeAgent()
response = await agent.chat("Hello, how are you?")
print(response)
```

### With Conversation History
```python
agent = WorkingFreeAgent()
await agent.chat("My name is John")
await agent.chat("What's my name?")  # Will remember context
```

### Using the Full Framework
```python
from ai_agent.core.agent import Agent
from ai_agent.core.config import Config

config = Config()
agent = Agent(config)
response = await agent.chat("Hello!")
```

## ğŸ“Š Available Commands

While running the agent:
- `quit` or `exit`: Exit the chat
- `clear`: Clear conversation history
- `summary`: Show conversation statistics

### Option 2: Interactive Chat

```bash
python -m ai_agent chat
```

This starts an interactive chat session with commands like:
- `help` - Show available commands
- `models` - List available models
- `model <name>` - Switch models
- `clear` - Clear conversation
- `quit` - Exit

### Option 3: Single Questions

```bash
python -m ai_agent ask "What is artificial intelligence?"
```

### Option 4: Show Information

```bash
python -m ai_agent info
python -m ai_agent models
```

## ğŸ› ï¸ Development Commands

### VS Code Tasks (Ctrl+Shift+P â†’ "Run Task")

- **Install Dependencies** - Install/update Python packages
- **Run Example** - Run the example script
- **Start Chat** - Start interactive chat session
- **Run Tests** - Run the test suite
- **Format Code** - Format code with Black
- **Type Check** - Run MyPy type checking

### VS Code Launch Configurations (F5)

- **Run Example** - Debug the example script
- **Start Chat Session** - Debug interactive chat
- **Ask Single Question** - Debug single question mode
- **Show Agent Info** - Debug info command
- **List Available Models** - Debug models command
- **Run Tests** - Debug test suite

## ğŸ“ Project Structure

```
ai_agent/
â”œâ”€â”€ ai_agent/              # Main package
â”‚   â”œâ”€â”€ core/             # Core functionality
â”‚   â”‚   â”œâ”€â”€ agent.py      # Main AI agent class
â”‚   â”‚   â”œâ”€â”€ conversation.py # Conversation management
â”‚   â”‚   â””â”€â”€ config.py     # Configuration management
â”‚   â”œâ”€â”€ models/           # Language model integrations
â”‚   â”‚   â”œâ”€â”€ base.py       # Base model interface
â”‚   â”‚   â”œâ”€â”€ openai_model.py # OpenAI integration
â”‚   â”‚   â””â”€â”€ anthropic_model.py # Anthropic integration
â”‚   â”œâ”€â”€ plugins/          # Plugin system
â”‚   â”‚   â”œâ”€â”€ base.py       # Base plugin interface
â”‚   â”‚   â””â”€â”€ examples/     # Example plugins
â”‚   â”œâ”€â”€ utils/            # Utility functions
â”‚   â””â”€â”€ cli.py            # Command-line interface
â”œâ”€â”€ tests/                # Test suite
â”œâ”€â”€ example.py            # Example usage script
â”œâ”€â”€ requirements.txt      # Dependencies
â””â”€â”€ README.md            # Documentation
```

## ğŸ”Œ Extending the Agent

### Adding New Models

1. Create a new model class in `ai_agent/models/`
2. Inherit from `BaseModel`
3. Implement required methods: `generate()`, `generate_stream()`, `is_available()`
4. Register in `AIAgent._initialize_models()`

### Adding New Plugins

1. Create a new plugin class in `ai_agent/plugins/`
2. Inherit from `BasePlugin`
3. Implement required methods: `execute()`, `get_capabilities()`
4. Register in `AIAgent._initialize_plugins()`

### Example Plugin

```python
from ai_agent.plugins.base import BasePlugin, PluginResult

class MyPlugin(BasePlugin):
    def __init__(self):
        super().__init__("my_plugin", "My custom plugin")
    
    async def execute(self, *args, **kwargs):
        # Your plugin logic here
        return PluginResult(success=True, data="result")
    
    def get_capabilities(self):
        return ["capability1", "capability2"]
```

## ğŸ§ª Testing

Run the test suite:

```bash
python -m pytest tests/ -v
```

## ğŸ¨ Code Quality

Format code:

```bash
python -m black ai_agent/ tests/ example.py
```

Type checking:

```bash
python -m mypy ai_agent/
```

## ğŸš€ Next Steps

1. **Set up your API keys** in `.env`
2. **Run the example** to see it in action
3. **Try the interactive chat** for a full experience
4. **Explore the plugin system** to add custom functionality
5. **Read the code** to understand the architecture
6. **Write tests** for any new features you add

## ğŸ“š Additional Resources

- [OpenAI API Documentation](https://platform.openai.com/docs)
- [Anthropic API Documentation](https://docs.anthropic.com/)
- [Rich Console Documentation](https://rich.readthedocs.io/)
- [Click CLI Documentation](https://click.palletsprojects.com/)

Happy coding! ğŸ‰
